"""
config_engine.py - é…ç½®å¼•æ“

èŒè´£ï¼š
- ç«™ç‚¹é…ç½®åŠ è½½/ä¿å­˜
- AI è‡ªåŠ¨è¯†åˆ«é¡µé¢é€‰æ‹©å™¨
- é€‰æ‹©å™¨éªŒè¯ä¸ä¿®å¤
- é…ç½®æ–‡ä»¶çƒ­æ›´æ–°ä¸å¿«ç…§ç®¡ç†
"""

import json
import os
import re
import time
import logging
import copy  # Added for snapshot
from typing import Dict, Optional, List, Any
from urllib import request, error
import bs4
from bs4 import BeautifulSoup

from data_models import SiteConfig, WorkflowStep, AIAnalysisResult


# ================= å¸¸é‡é…ç½® =================

class ConfigConstants:
    """é…ç½®å¼•æ“å¸¸é‡"""
    # æ–‡ä»¶é…ç½®
    CONFIG_FILE = os.getenv("SITES_CONFIG_FILE", "sites.json")
    
    # AI é…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡ï¼‰
    HELPER_API_KEY = os.getenv("HELPER_API_KEY", "lumingya")
    HELPER_BASE_URL = os.getenv("HELPER_BASE_URL", "http://127.0.0.1:5104/v1")
    HELPER_MODEL = os.getenv("HELPER_MODEL", "gemini-3-pro")
    
    # HTML å¤„ç†
    MAX_HTML_CHARS = int(os.getenv("MAX_HTML_CHARS", "120000"))
    TEXT_TRUNCATE_LENGTH = 80
    
    # AI é‡è¯•
    AI_MAX_RETRIES = 3
    AI_RETRY_BASE_DELAY = 1.0  # åˆå§‹å»¶è¿Ÿ
    AI_RETRY_MAX_DELAY = 10.0  # æœ€å¤§å»¶è¿Ÿ
    AI_REQUEST_TIMEOUT = 120
    
    # éšèº«æ¨¡å¼ç«™ç‚¹
    STEALTH_DOMAINS = ['lmarena.ai', 'poe.com', 'you.com', 'chatgpt.com']


# é»˜è®¤å·¥ä½œæµ
# æ³¨æ„ï¼šSTREAM_WAIT æ­¥éª¤ä¼šä½¿ç”¨ result_container é€‰æ‹©å™¨
# å¦‚æœé…ç½®äº† message_wrapperï¼Œä¼šç”¨äºå®šä½å®Œæ•´æ¶ˆæ¯å®¹å™¨
# å¦‚æœé…ç½®äº† generating_indicatorï¼Œä¼šç”¨äºæ£€æµ‹ç”ŸæˆçŠ¶æ€
DEFAULT_WORKFLOW: List[WorkflowStep] = [
    {"action": "CLICK", "target": "new_chat_btn", "optional": True, "value": None},
    {"action": "WAIT", "target": "", "optional": False, "value": "0.5"},
    {"action": "FILL_INPUT", "target": "input_box", "optional": False, "value": None},
    {"action": "CLICK", "target": "send_btn", "optional": True, "value": None},
    {"action": "KEY_PRESS", "target": "Enter", "optional": True, "value": None},
    {"action": "STREAM_WAIT", "target": "result_container", "optional": False, "value": None}
]

# é€šç”¨å›é€€é€‰æ‹©å™¨
FALLBACK_SELECTORS = {
    "input_box": "textarea",
    "send_btn": "button[type=\"submit\"]",
    "result_container": "div",
    "new_chat_btn": None,
    # å¯é€‰å­—æ®µï¼Œç”¨äºæ”¹è¿›æµå¼ç›‘å¬
    "message_wrapper": None,        # æ¶ˆæ¯å®Œæ•´å®¹å™¨ï¼ˆç”¨äºå¤šèŠ‚ç‚¹æ‹¼æ¥ï¼‰
    "generating_indicator": None,   # ç”Ÿæˆä¸­æŒ‡ç¤ºå™¨ï¼ˆæ£€æµ‹æ˜¯å¦è¿˜åœ¨è¾“å‡ºï¼‰
}

# æ— æ•ˆé€‰æ‹©å™¨è¯­æ³•æ¨¡å¼
INVALID_SYNTAX_PATTERNS = [
    (r'~\s*\.\.', '~ .. æ— æ•ˆè¯­æ³•'),
    (r'\.\.\s*$', 'ç»“å°¾ .. æ— æ•ˆ'),
    (r'>>\s', '>> æ— æ•ˆè¯­æ³•'),
    (r':has\(', ':has() å…¼å®¹æ€§å·®'),
    (r'\s~\s*$', 'ç»“å°¾ ~ æ— æ•ˆ'),
]


# ================= æ—¥å¿—é…ç½® =================

logger = logging.getLogger('config_engine')
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('[%(asctime)s] %(levelname)s [Config] %(message)s', datefmt='%H:%M:%S')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)


# ================= HTML æ¸…ç†å™¨ =================

class HTMLCleaner:
    """HTML æ¸…ç†å™¨ - ç‹¬ç«‹èŒè´£"""
    
    # è¦ç§»é™¤çš„æ ‡ç­¾
    TAGS_TO_REMOVE = [
        'script', 'style', 'meta', 'link', 'noscript',
        'img', 'video', 'audio', 'iframe', 'canvas',
        'path', 'rect', 'circle', 'polygon', 'defs', 'clipPath',
        'header', 'footer', 'nav', 'aside',  # ç§»é™¤éæ ¸å¿ƒåŒºåŸŸ
    ]
    
    # ä¿ç•™çš„å±æ€§
    ALLOWED_ATTRS = [
        'id', 'class', 'name', 'placeholder', 'aria-label', 'role',
        'data-testid', 'type', 'disabled', 'value', 'title', 'tabindex',
        'contenteditable', 'href'
    ]
    
    # äº¤äº’å…ƒç´ æ ‡ç­¾ï¼ˆå¿…é¡»ä¿ç•™ï¼‰
    INTERACTIVE_TAGS = ['input', 'textarea', 'button', 'form', 'a']
    
    # æ ¸å¿ƒåŒºåŸŸé€‰æ‹©å™¨ï¼ˆä¼˜å…ˆä¿ç•™ï¼‰
    CORE_AREA_SELECTORS = [
        '[role="main"]',
        'main',
        '#app',
        '#root',
        '.chat',
        '.conversation',
        '.message',
    ]
    
    def __init__(self, max_chars: int = None, text_truncate: int = None):
        self.max_chars = max_chars or ConfigConstants.MAX_HTML_CHARS
        self.text_truncate = text_truncate or ConfigConstants.TEXT_TRUNCATE_LENGTH
    
    def clean(self, html: str) -> str:
        """æ·±åº¦æ¸…ç† HTML"""
        logger.debug("å¼€å§‹ HTML æ¸…ç†...")
        original_length = len(html)
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # 1. æå–æ‰€æœ‰äº¤äº’å…ƒç´ ï¼ˆåœ¨åˆ é™¤ä»»ä½•å†…å®¹å‰ï¼‰
        interactive_elements = self._extract_interactive_elements(soup)
        
        # 2. ç§»é™¤éå¿…è¦æ ‡ç­¾
        for tag in soup(self.TAGS_TO_REMOVE):
            tag.decompose()
        
        # 3. ç§»é™¤æ³¨é‡Š
        for element in soup(text=lambda t: isinstance(t, bs4.element.Comment)):
            element.extract()
        
        # 4. æ¸…ç†å±æ€§å’Œæˆªæ–­æ–‡æœ¬
        for tag in soup.find_all(True):
            if tag.string and len(tag.string) > self.text_truncate:
                tag.string = tag.string[:self.text_truncate] + "..."
            
            attrs = dict(tag.attrs)
            for attr in attrs:
                if attr not in self.ALLOWED_ATTRS:
                    del tag.attrs[attr]
            
            if 'class' in tag.attrs and isinstance(tag.attrs['class'], list):
                tag.attrs['class'] = " ".join(tag.attrs['class'])
        
        # 5. è·å–æ¸…ç†åçš„ HTML
        clean_html = str(soup.body) if soup.body else str(soup)
        clean_html = re.sub(r'\s+', ' ', clean_html).strip()
        
        # 6. æ™ºèƒ½æˆªæ–­ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if len(clean_html) > self.max_chars:
            logger.warning(f"HTML è¿‡é•¿ ({len(clean_html)})ï¼Œæ‰§è¡Œæ™ºèƒ½æˆªæ–­...")
            clean_html = self._smart_truncate(clean_html, interactive_elements)
        
        final_length = len(clean_html)
        reduction = 100 - (final_length / original_length * 100) if original_length > 0 else 0
        logger.info(f"HTML æ¸…ç†å®Œæˆ: {original_length} â†’ {final_length} å­—ç¬¦ (å‡å°‘ {reduction:.1f}%)")
        
        return clean_html
    
    def _extract_interactive_elements(self, soup: BeautifulSoup) -> str:
        """æå–æ‰€æœ‰äº¤äº’å…ƒç´ çš„ HTML ç‰‡æ®µ"""
        elements = []
        
        for tag_name in self.INTERACTIVE_TAGS:
            for element in soup.find_all(tag_name):
                # è·å–å…ƒç´ åŠå…¶çˆ¶çº§ä¸Šä¸‹æ–‡ï¼ˆä¿ç•™ 2 å±‚çˆ¶çº§ï¼‰
                context = self._get_element_with_context(element, levels=2)
                if context:
                    elements.append(context)
        
        # å»é‡
        unique_elements = list(dict.fromkeys(elements))
        return "\n".join(unique_elements)
    
    def _get_element_with_context(self, element, levels: int = 2) -> str:
        """è·å–å…ƒç´ åŠå…¶çˆ¶çº§ä¸Šä¸‹æ–‡"""
        try:
            # å‘ä¸Šæ‰¾çˆ¶çº§
            current = element
            for _ in range(levels):
                if current.parent and current.parent.name not in ['body', 'html', '[document]']:
                    current = current.parent
                else:
                    break
            
            # ç®€åŒ–è¾“å‡ºï¼šåªä¿ç•™å…³é”®å±æ€§
            html_str = str(current)
            # æˆªæ–­è¿‡é•¿çš„å•ä¸ªå…ƒç´ 
            if len(html_str) > 2000:
                html_str = html_str[:2000] + "..."
            return html_str
        except Exception:
            return str(element)
    
    def _smart_truncate(self, html: str, interactive_html: str) -> str:
        """
        æ™ºèƒ½æˆªæ–­ç­–ç•¥ï¼š
        1. ç¡®ä¿äº¤äº’å…ƒç´ å§‹ç»ˆåŒ…å«
        2. åœ¨æ ‡ç­¾è¾¹ç•Œæˆªæ–­ï¼Œä¸ç ´å HTML ç»“æ„
        3. ä¿ç•™é¦–å°¾ + ä¸­é—´æ ¸å¿ƒåŒºåŸŸ
        """
        # äº¤äº’å…ƒç´ é¢„ç®—ï¼šæœ€å¤šå ç”¨ 30% ç©ºé—´
        interactive_budget = int(self.max_chars * 0.3)
        if len(interactive_html) > interactive_budget:
            interactive_html = interactive_html[:interactive_budget]
        
        # å‰©ä½™é¢„ç®—åˆ†é…ç»™ä¸» HTML
        remaining_budget = self.max_chars - len(interactive_html) - 100  # 100 for markers
        
        if remaining_budget <= 0:
            # äº¤äº’å…ƒç´ å·²ç»è¶…å‡ºé¢„ç®—ï¼Œåªè¿”å›äº¤äº’å…ƒç´ 
            logger.warning("äº¤äº’å…ƒç´ å·²å æ»¡é¢„ç®—")
            return interactive_html
        
        # å°è¯•æ‰¾åˆ°æ ¸å¿ƒåŒºåŸŸ
        core_html = self._extract_core_area(html)
        if core_html and len(core_html) <= remaining_budget:
            # æ ¸å¿ƒåŒºåŸŸåœ¨é¢„ç®—å†…ï¼Œä½¿ç”¨æ ¸å¿ƒåŒºåŸŸ + äº¤äº’å…ƒç´ 
            result = core_html + "\n<!-- INTERACTIVE ELEMENTS -->\n" + interactive_html
            return result[:self.max_chars]
        
        # å›é€€ï¼šé¦–å°¾å„å–ä¸€éƒ¨åˆ† + äº¤äº’å…ƒç´ 
        head_budget = remaining_budget // 3
        tail_budget = remaining_budget // 3
        
        # åœ¨æ ‡ç­¾è¾¹ç•Œæˆªæ–­
        head_part = self._truncate_at_tag_boundary(html[:head_budget * 2], head_budget, from_end=False)
        tail_part = self._truncate_at_tag_boundary(html[-tail_budget * 2:], tail_budget, from_end=True)
        
        result = (
            head_part +
            "\n<!-- TRUNCATED: MIDDLE SECTION -->\n" +
            "<!-- INTERACTIVE ELEMENTS START -->\n" +
            interactive_html +
            "\n<!-- INTERACTIVE ELEMENTS END -->\n" +
            tail_part
        )
        
        # æœ€ç»ˆé•¿åº¦æ£€æŸ¥
        if len(result) > self.max_chars:
            result = result[:self.max_chars]
        
        return result
    
    def _extract_core_area(self, html: str) -> Optional[str]:
        """å°è¯•æå–æ ¸å¿ƒåŒºåŸŸ"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            for selector in self.CORE_AREA_SELECTORS:
                try:
                    element = soup.select_one(selector)
                    if element:
                        core_html = str(element)
                        logger.debug(f"æ‰¾åˆ°æ ¸å¿ƒåŒºåŸŸ: {selector} ({len(core_html)} chars)")
                        return core_html
                except Exception:
                    continue
            
            return None
        except Exception as e:
            logger.debug(f"æå–æ ¸å¿ƒåŒºåŸŸå¤±è´¥: {e}")
            return None
    
    def _truncate_at_tag_boundary(self, html: str, max_len: int, from_end: bool = False) -> str:
        """
        åœ¨æ ‡ç­¾è¾¹ç•Œæˆªæ–­ï¼Œé¿å…ç ´å HTML ç»“æ„
        
        Args:
            html: HTML å­—ç¬¦ä¸²
            max_len: æœ€å¤§é•¿åº¦
            from_end: True è¡¨ç¤ºä»æœ«å°¾å¼€å§‹ä¿ç•™
        """
        if len(html) <= max_len:
            return html
        
        if from_end:
            # ä»æœ«å°¾ä¿ç•™ï¼šæ‰¾åˆ°åˆé€‚çš„èµ·å§‹ä½ç½®
            start_pos = len(html) - max_len
            # å‘åæ‰¾ç¬¬ä¸€ä¸ª < ä½œä¸ºèµ·å§‹
            tag_start = html.find('<', start_pos)
            if tag_start != -1 and tag_start < len(html) - 100:
                return html[tag_start:]
            return html[-max_len:]
        else:
            # ä»å¼€å¤´ä¿ç•™ï¼šæ‰¾åˆ°åˆé€‚çš„ç»“æŸä½ç½®
            # å‘å‰æ‰¾æœ€åä¸€ä¸ª > ä½œä¸ºç»“æŸ
            tag_end = html.rfind('>', 0, max_len)
            if tag_end != -1 and tag_end > 100:
                return html[:tag_end + 1]
            return html[:max_len]


# ================= é€‰æ‹©å™¨éªŒè¯å™¨ =================

class SelectorValidator:
    """é€‰æ‹©å™¨éªŒè¯å™¨"""
    
    def validate(self, selectors: Dict[str, Optional[str]]) -> Dict[str, Optional[str]]:
        """éªŒè¯å¹¶ä¿®å¤é€‰æ‹©å™¨"""
        fixed = {}
        
        for key, selector in selectors.items():
            if selector is None:
                fixed[key] = FALLBACK_SELECTORS.get(key)
                continue
            
            is_invalid = False
            invalid_reason = ""
            
            for pattern, reason in INVALID_SYNTAX_PATTERNS:
                if re.search(pattern, selector):
                    is_invalid = True
                    invalid_reason = reason
                    break
            
            if is_invalid:
                logger.warning(f"âŒ æ— æ•ˆé€‰æ‹©å™¨ [{key}]: {selector}")
                logger.warning(f"   åŸå› : {invalid_reason}")
                
                repaired = self._try_repair(selector)
                if repaired:
                    logger.info(f"   âœ… ä¿®å¤ä¸º: {repaired}")
                    fixed[key] = repaired
                else:
                    fallback = FALLBACK_SELECTORS.get(key)
                    logger.info(f"   ğŸ”„ å›é€€ä¸º: {fallback}")
                    fixed[key] = fallback
            else:
                if re.search(r'\._[a-f0-9]{5,}|^\.[a-f0-9]{6,}', selector):
                    logger.info(f"â„¹ï¸  å“ˆå¸Œç±»å [{key}]: {selector} (å¯èƒ½ä¸ç¨³å®šï¼Œä½†ä¿ç•™)")
                
                fixed[key] = selector
        
        return fixed
    
    def _try_repair(self, selector: str) -> Optional[str]:
        """å°è¯•ä¿®å¤é€‰æ‹©å™¨"""
        tag_match = re.match(r'^(\w+)', selector)
        if not tag_match:
            return None
        
        tag = tag_match.group(1)
        
        attr_patterns = [
            r'(\[name=["\']?\w+["\']?\])',
            r'(\[type=["\']?\w+["\']?\])',
            r'(\[role=["\']?\w+["\']?\])',
            r'(#[\w-]+)',
        ]
        
        for pattern in attr_patterns:
            match = re.search(pattern, selector)
            if match:
                return tag + match.group(1)
        
        return tag


# ================= AI åˆ†æå™¨ =================

class AIAnalyzer:
    """AI é¡µé¢åˆ†æå™¨"""
    
    def __init__(self):
        self.api_key = ConfigConstants.HELPER_API_KEY
        self.base_url = ConfigConstants.HELPER_BASE_URL.rstrip('/')
        self.model = ConfigConstants.HELPER_MODEL
        
        if not self.api_key:
            logger.warning("âš ï¸  æœªé…ç½® HELPER_API_KEYï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def analyze(self, html: str) -> Optional[Dict[str, str]]:
        """åˆ†æ HTML å¹¶è¿”å›é€‰æ‹©å™¨"""
        if not self.api_key:
            logger.error("API Key æœªé…ç½®")
            return None
        
        prompt = self._build_prompt(html)
        
        for attempt in range(ConfigConstants.AI_MAX_RETRIES):
            try:
                logger.info(f"æ­£åœ¨è¯·æ±‚ AI åˆ†æï¼ˆå°è¯• {attempt + 1}/{ConfigConstants.AI_MAX_RETRIES}ï¼‰...")
                
                response = self._request_ai(prompt)
                if response:
                    selectors = self._extract_json(response)
                    if selectors:
                        logger.info("âœ… AI åˆ†ææˆåŠŸ")
                        return selectors
                
                logger.warning(f"ç¬¬ {attempt + 1} æ¬¡åˆ†æå¤±è´¥")
            
            except Exception as e:
                logger.error(f"AI è¯·æ±‚å¼‚å¸¸: {e}")
            
            if attempt < ConfigConstants.AI_MAX_RETRIES - 1:
                delay = min(
                    ConfigConstants.AI_RETRY_BASE_DELAY * (2 ** attempt),
                    ConfigConstants.AI_RETRY_MAX_DELAY
                )
                jitter = delay * 0.1 * (0.5 - os.urandom(1)[0] / 255)
                sleep_time = delay + jitter
                
                logger.info(f"ç­‰å¾… {sleep_time:.2f}s åé‡è¯•...")
                time.sleep(sleep_time)
        
        logger.error("âŒ AI åˆ†æå¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰")
        return None
    
    def _request_ai(self, prompt: str) -> Optional[str]:
        """å‘ AI API å‘é€è¯·æ±‚"""
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }
        data = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1
        }
        
        try:
            req = request.Request(
                url,
                data=json.dumps(data).encode('utf-8'),
                headers=headers
            )
            
            with request.urlopen(req, timeout=ConfigConstants.AI_REQUEST_TIMEOUT) as response:
                response_text = response.read().decode('utf-8')
            
            try:
                json_resp = json.loads(response_text)
                if "choices" in json_resp and len(json_resp['choices']) > 0:
                    return json_resp['choices'][0]['message']['content']
            except json.JSONDecodeError:
                logger.error("AI å“åº”è§£æå¤±è´¥")
            
            return None
        
        except error.HTTPError as e:
            logger.error(f"HTTP é”™è¯¯ {e.code}: {e.reason}")
            return None
        except error.URLError as e:
            logger.error(f"ç½‘ç»œé”™è¯¯: {e.reason}")
            return None
        except TimeoutError:
            logger.error("è¯·æ±‚è¶…æ—¶")
            return None
    
    def _build_prompt(self, clean_html: str) -> str:
        """æ„å»º AI æç¤ºè¯"""
        lines = [
            "You are a web scraping expert. Analyze this AI chat interface HTML to identify critical elements.",
            "",
            "## CRITICAL RULES:",
            "1. **Uniqueness is Key**: Ensure selectors matches ONLY the intended element.",
            "2. **Distinguish AI vs User**: For `result_container`, specificy the selector to target the **AI's response text** only. It MUST exclude user prompts, sidebars, or chat history.",
            "3. **Use Hierarchy**: If a class like `.prose` or `.markdown` is used for both User and AI, you MUST find a unique parent class to differentiate (e.g., `.bot-msg .prose`).",
            "4. **Syntax**: Use standard CSS selectors. Spaces for descendants (e.g., `div.bot p`) are encouraged for precision.",
            "5. **No Invalid Syntax**: Do NOT use `xpath`, `~`, `:has()`, or `text()`.",
            "",
            "## PREFERENCE ORDER:",
            "1. `id`, `name`, `data-testid` (Most preferred)",
            "2. `button[type=\"submit\"]`",
            "3. Unique parent class + target class (e.g., `.response-area .content`)",
            "4. Hashed classes (only if no other option exists)",
            "",
            "## REQUIRED OUTPUT (JSON ONLY):",
            "Return a JSON object with these 6 keys:",
            "- `input_box`: The text input area (textarea/input).",
            "- `send_btn`: The button that sends the message (usually type=\"submit\").",
            "- `result_container`: The container for the AI's generated text response. **(Check parent containers to ensure it excludes user bubbles)**.",
            "- `new_chat_btn`: Button or Link to start a fresh conversation (or null).",
            "- `message_wrapper`: (Optional) The outer container that wraps a complete message turn, including thinking process and response. Usually has `data-turn-role` or similar attribute. Set to null if not identifiable.",
            "- `generating_indicator`: (Optional) Element that indicates AI is still generating (e.g., stop button, loading spinner). Set to null if not identifiable.",
            "",
            "## HTML:",
            clean_html
        ]
        return "\n".join(lines)
    
    def _extract_json(self, text: str) -> Optional[Dict]:
        """ä» AI å“åº”ä¸­æå– JSON"""
        try:
            match = re.search(r'```(?:json)?\s*(\{[\s\S]*?\})\s*```', text)
            if match:
                return json.loads(match.group(1))
            
            match = re.search(r'(\{[\s\S]*\})', text)
            if match:
                return json.loads(match.group(1))
            
            return json.loads(text)
        
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}")
            return None


# ================= é…ç½®å¼•æ“ =================

class ConfigEngine:
    """é…ç½®å¼•æ“ä¸»ç±»"""
    
    def __init__(self):
        self.config_file = ConfigConstants.CONFIG_FILE
        self.last_mtime = 0.0  # è®°å½•æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´
        self.sites: Dict[str, SiteConfig] = self._load_config()
        
        self.html_cleaner = HTMLCleaner()
        self.validator = SelectorValidator()
        self.ai_analyzer = AIAnalyzer()
        
        logger.info(f"é…ç½®å¼•æ“å·²åˆå§‹åŒ–ï¼Œå·²åŠ è½½ {len(self.sites)} ä¸ªç«™ç‚¹é…ç½®")
    
    def _load_config(self) -> Dict[str, SiteConfig]:
        """åˆå§‹åŒ–åŠ è½½é…ç½®æ–‡ä»¶"""
        if not os.path.exists(self.config_file):
            logger.info(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return {}
        
        try:
            # è®°å½•ä¿®æ”¹æ—¶é—´
            self.last_mtime = os.path.getmtime(self.config_file)
            
            with open(self.config_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    return {}
                
                data = json.loads(content)
                logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file} (mtime: {self.last_mtime})")
                return data
        
        except json.JSONDecodeError as e:
            logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            return {}
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return {}
    
    def refresh_if_changed(self):
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™é‡è½½
        ç”¨äº get_site_config å¼€å¤´ï¼Œå®ç°çƒ­æ›´æ–°
        """
        if not os.path.exists(self.config_file):
            return

        try:
            current_mtime = os.path.getmtime(self.config_file)
            # å¦‚æœä¿®æ”¹æ—¶é—´æœ‰å˜åŒ–ï¼Œå°è¯•é‡è½½
            if current_mtime != self.last_mtime:
                logger.info(f"âš¡ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ– (new mtime: {current_mtime})")
                self.reload_config()
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–‡ä»¶å˜åŒ–å¤±è´¥: {e}")

    def reload_config(self):
        """
        é‡æ–°åŠ è½½é…ç½®ï¼ˆHot Reloadï¼‰
        è§£æå¤±è´¥æ—¶ä¿ç•™æ—§é…ç½®ï¼Œä¸è¦†ç›–
        """
        if not os.path.exists(self.config_file):
            logger.warning("é‡è½½å¤±è´¥ï¼šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return

        try:
            # å…ˆè¯»å– mtime
            mtime = os.path.getmtime(self.config_file)
            
            with open(self.config_file, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    data = {}
                else:
                    data = json.loads(content)
            
            # åªæœ‰è§£ææˆåŠŸæ‰æ›´æ–°
            self.sites = data
            self.last_mtime = mtime
            logger.info(f"âœ… é…ç½®å·²çƒ­é‡è½½ (Sites: {len(self.sites)})")
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ é‡è½½é…ç½®å¤±è´¥ï¼ˆJSONæ ¼å¼é”™è¯¯ï¼‰ï¼Œä¿ç•™æ—§é…ç½®: {e}")
        except Exception as e:
            logger.error(f"âŒ é‡è½½é…ç½®å¤±è´¥: {e}")

    def _save_config(self):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, "w", encoding="utf-8") as f:
                json.dump(self.sites, f, indent=2, ensure_ascii=False)
            
            # å†™å…¥åæ›´æ–° last_mtimeï¼Œé˜²æ­¢è‡ªå·±å†™å…¥è§¦å‘ refresh_if_changed çš„é‡è½½
            if os.path.exists(self.config_file):
                self.last_mtime = os.path.getmtime(self.config_file)
            
            logger.info(f"é…ç½®å·²ä¿å­˜: {self.config_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def get_site_config(self, domain: str, html_content: str) -> Optional[SiteConfig]:
        """
        è·å–ç«™ç‚¹é…ç½®ï¼ˆç¼“å­˜ + AI åˆ†æï¼‰
        
        Args:
            domain: åŸŸå
            html_content: é¡µé¢ HTML
            
        Returns:
            ç«™ç‚¹é…ç½®çš„å¿«ç…§ï¼ˆå‰¯æœ¬ï¼‰
        """
        # 1. å°è¯•çƒ­æ›´æ–°ï¼šæ£€æŸ¥æ–‡ä»¶å˜åŒ–
        self.refresh_if_changed()

        # æ£€æŸ¥ç¼“å­˜
        if domain in self.sites:
            config = self.sites[domain]
            
            # ç¡®ä¿æœ‰ workflow
            if "workflow" not in config:
                config["workflow"] = DEFAULT_WORKFLOW
                self.sites[domain] = config
                self._save_config()
            
            logger.debug(f"ä½¿ç”¨ç¼“å­˜é…ç½®: {domain}")
            # è¿”å›æ·±æ‹·è´å¿«ç…§ï¼Œä¿è¯ browser_core ä½¿ç”¨æœŸé—´é…ç½®ä¸è¢«å¤–éƒ¨ä¿®æ”¹å½±å“
            return copy.deepcopy(config)
        
        # AI è¯†åˆ«
        logger.info(f"ğŸ” æœªçŸ¥åŸŸå {domain}ï¼Œå¯åŠ¨ AI è¯†åˆ«...")
        
        # æ¸…ç† HTML
        clean_html = self.html_cleaner.clean(html_content)
        
        # AI åˆ†æ
        selectors = self.ai_analyzer.analyze(clean_html)
        
        if selectors:
            # éªŒè¯é€‰æ‹©å™¨
            selectors = self.validator.validate(selectors)
            
            # æ„å»ºé…ç½®
            new_config: SiteConfig = {
                "selectors": selectors,
                "workflow": DEFAULT_WORKFLOW,
                "stealth": self._guess_stealth(domain),
                # å¯é€‰ï¼šæµå¼ç›‘æ§é…ç½®ï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
                "stream_config": {
                    "silence_threshold": 2.5,    # é™é»˜é˜ˆå€¼ï¼ˆç§’ï¼‰
                    "initial_wait": 30.0,        # åˆå§‹ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
                    "enable_wrapper_search": True  # æ˜¯å¦å¯ç”¨å®¹å™¨å‘ä¸ŠæŸ¥æ‰¾
                }
            }
            
            # ä¿å­˜
            self.sites[domain] = new_config
            self._save_config()
            
            logger.info(f"âœ… é…ç½®å·²ç”Ÿæˆå¹¶ä¿å­˜: {domain}")
            return copy.deepcopy(new_config)
        
        # ä½¿ç”¨å›é€€é…ç½®
        logger.warning(f"âš ï¸  AI åˆ†æå¤±è´¥ï¼Œä½¿ç”¨é€šç”¨å›é€€é…ç½®: {domain}")
        fallback_config: SiteConfig = {
            "selectors": FALLBACK_SELECTORS.copy(),
            "workflow": DEFAULT_WORKFLOW,
            "stealth": False,
            "stream_config": {
                "silence_threshold": 2.5,
                "initial_wait": 30.0,
                "enable_wrapper_search": True
            }
        }
        
        self.sites[domain] = fallback_config
        self._save_config()
        
        return copy.deepcopy(fallback_config)
    
    def _guess_stealth(self, domain: str) -> bool:
        """æ¨æµ‹æ˜¯å¦éœ€è¦éšèº«æ¨¡å¼"""
        for stealth_domain in ConfigConstants.STEALTH_DOMAINS:
            if stealth_domain in domain:
                logger.info(f"æ£€æµ‹åˆ°éœ€è¦éšèº«æ¨¡å¼çš„åŸŸå: {domain}")
                return True
        return False
    
    def delete_site_config(self, domain: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šç«™ç‚¹é…ç½®
        """
        # åˆ é™¤å‰ä¹Ÿæ£€æŸ¥ä¸€ä¸‹æ˜¯å¦æœ‰æ–°é…ç½®ï¼Œé¿å…è¦†ç›–ä»–äººæ›´æ”¹ï¼ˆå¯é€‰ï¼Œè§†å¹¶å‘éœ€æ±‚è€Œå®šï¼‰
        self.refresh_if_changed()
        
        if domain in self.sites:
            del self.sites[domain]
            self._save_config()
            logger.info(f"å·²åˆ é™¤é…ç½®: {domain}")
            return True
        return False


# ================= å•ä¾‹ =================

config_engine = ConfigEngine()


# ================= æµ‹è¯•å…¥å£ =================

if __name__ == "__main__":
    logging.getLogger('config_engine').setLevel(logging.DEBUG)
    
    try:
        from DrissionPage import ChromiumPage
        
        print("è¿æ¥æµè§ˆå™¨...")
        # ä»…æµ‹è¯•ï¼Œä¸å®é™…è¿æ¥
        print(f"å½“å‰é…ç½®é¡¹æ•°é‡: {len(config_engine.sites)}")
        
        # æ¨¡æ‹Ÿæ–‡ä»¶æ›´æ–°æµ‹è¯•
        print("\n--- æ¨¡æ‹Ÿçƒ­æ›´æ–°æµ‹è¯• ---")
        original_mtime = config_engine.last_mtime
        print(f"åˆå§‹ mtime: {original_mtime}")
        
        # å¼ºåˆ¶ä¿å­˜ä¸€æ¬¡ï¼Œåº”è¯¥æ›´æ–° mtime
        config_engine._save_config()
        print(f"ä¿å­˜å mtime: {config_engine.last_mtime}")
        
        if config_engine.last_mtime != original_mtime:
            print("âœ… _save_config æˆåŠŸæ›´æ–°äº† mtime")
        
        # æ¨¡æ‹Ÿå¤–éƒ¨ä¿®æ”¹
        print("\n--- æ¨¡æ‹Ÿå¤–éƒ¨ä¿®æ”¹ sites.json ---")
        time.sleep(1.1) # ç¡®ä¿ mtime å˜åŒ–
        try:
            with open("sites.json", "w", encoding="utf-8") as f:
                json.dump({"test.com": {"selectors": {}, "workflow": []}}, f)
            print("å¤–éƒ¨æ–‡ä»¶å·²å†™å…¥")
            
            # è°ƒç”¨ refresh_if_changed
            print("è°ƒç”¨ refresh_if_changed()...")
            config_engine.refresh_if_changed()
            
            if "test.com" in config_engine.sites:
                print("âœ… çƒ­æ›´æ–°æˆåŠŸï¼Œæ£€æµ‹åˆ° test.com")
            else:
                print("âŒ çƒ­æ›´æ–°å¤±è´¥")
                
        except Exception as e:
            print(f"æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
            
    except Exception as e:

        print(f"Error: {e}")
